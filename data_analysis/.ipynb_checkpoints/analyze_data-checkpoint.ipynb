{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nA note to other users:\\n\\nThis is roughly broken into 3 sections: The data_gathering() section which \\npulls data from the text files (stored in ../data , a directory just outside\\nof the directory that this program is being ran from), the data_analysis() section\\nwhich removes jump artifacts (an on-off happening at the same time, which is meaningless\\nto the evolution but is a side effect of allowing for more jumps than expected), and the\\nplot_data() section. These are called in order from a 'main' below the three sections. Keep in mind that\\njupyter keeps the most recently ran declaration/definition, so if you're making a change to a\\ndata_analysis() function for example, you must rerun that cell (shift+ENTER for most computers) in order\\nfor those changes to show up when calling 'main'. Similarly, if this is your first time opening the notebook\\nfor the day, you must run all of the cells in order for them to be loaded into memory.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "A note to other users:\n",
    "\n",
    "This is roughly broken into 3 sections: The data_gathering() section which \n",
    "pulls data from the text files (stored in ../data , a directory just outside\n",
    "of the directory that this program is being ran from), the data_analysis() section\n",
    "which removes jump artifacts (an on-off happening at the same time, which is meaningless\n",
    "to the evolution but is a side effect of allowing for more jumps than expected), and the\n",
    "plot_data() section. These are called in order from a 'main' below the three sections. Keep in mind that\n",
    "jupyter keeps the most recently ran declaration/definition, so if you're making a change to a\n",
    "data_analysis() function for example, you must rerun that cell (shift+ENTER for most computers) in order\n",
    "for those changes to show up when calling 'main'. Similarly, if this is your first time opening the notebook\n",
    "for the day, you must run all of the cells in order for them to be loaded into memory.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import errno\n",
    "from glob import glob\n",
    "from decimal import Decimal\n",
    "from pylab import *\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import glob\n",
    "import re\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from ast import literal_eval\n",
    "\n",
    "set_matplotlib_formats('pdf', 'png')\n",
    "plt.rcParams['savefig.dpi'] = 200\n",
    "plt.rcParams['figure.autolayout'] = False\n",
    "plt.rcParams['figure.figsize'] = 8,6\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['axes.titlesize'] = 18\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "plt.rcParams['lines.markersize'] = 4\n",
    "plt.rcParams['legend.fontsize'] = 20\n",
    "plt.rcParams['xtick.direction'] = 'out'\n",
    "plt.rcParams['ytick.direction'] = 'out'\n",
    "\n",
    "cmap=plt.cm.viridis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data gathering functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data():\n",
    "    data_mcbb_whole, data_mcbf_whole, data_adia_whole, data_mcdb_whole = [[],[]],[[],[]],[[],[]],[[],[]]\n",
    "\n",
    "    for my_dir in my_dirs:\n",
    "        for filepath in glob.iglob(my_dir + '*.txt'):\n",
    "            if 'MCBB' in filepath:\n",
    "                data_mcbb_whole[0].append(filepath)\n",
    "                data_mcbb_whole[1].append(get_data(filepath))\n",
    "            elif 'MCDB' in filepath:\n",
    "                data_mcdb_whole[0].append(filepath)\n",
    "                data_mcdb_whole[1].append(get_data(filepath)) \n",
    "            elif 'MCBF' in filepath:\n",
    "                data_mcbf_whole[0].append(filepath)\n",
    "                data_mcbf_whole[1].append(get_data(filepath))\n",
    "            elif 'ADIA' in filepath:\n",
    "                data_adia_whole[0].append(filepath)\n",
    "                data_adia_whole[1].append(get_data(filepath)) \n",
    "    find_optimal_seeds(data_mcbb_whole,data_mcdb_whole, data_mcbf_whole)\n",
    "    remove_non_monotonic_behavior(data_mcbb_whole,data_mcdb_whole, data_mcbf_whole)\n",
    "    return data_mcbb_whole, data_mcdb_whole, data_mcbf_whole, data_adia_whole\n",
    "\n",
    "\n",
    "\n",
    "def get_params(filepath):\n",
    "    names, values = [], []       \n",
    "    file = open(filepath, \"rt\")\n",
    "   \n",
    "    for line in file:\n",
    "        \n",
    "        if \"START_PARAMETERS\" in line: continue\n",
    "        if \"END_PARAMETERS\" in line: break\n",
    "            \n",
    "        line = line.rstrip(\"\\n\")\n",
    "        line_split = line.rstrip(\"\\n\").split(' ')\n",
    "        names.append(line_split[0].rstrip(\"=\")) \n",
    "        values.append(line_split[-1])\n",
    "        \n",
    "    return [names, values]\n",
    "\n",
    "\n",
    "def string_of_array_to_array_of_types(line, type):\n",
    "    string_array = (line.split('=')[1]).split(' ')\n",
    "    while ' ' in string_array: string_array.remove(' ')\n",
    "    while '' in string_array: string_array.remove('')\n",
    "    while ']' in string_array: string_array.remove(']')\n",
    "    string_array[0] = string_array[0].split(\"[\")[1]\n",
    "    string_array[-1] = string_array[-1].split(\"]\")[0]\n",
    "    for x in range(len(string_array)):string_array[x] = string_array[x].rstrip(',')\n",
    "    if(len(string_array)<= 1): return [0]\n",
    "    return [type(i) for i in string_array]\n",
    "\n",
    "\n",
    "def get_values(dictionary, name):\n",
    "    try:\n",
    "        names = dictionary[0]\n",
    "        values = dictionary[1]\n",
    "        index = names.index(name)\n",
    "        return values[index]\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def reshape_list(old_list, sub_array_indices):\n",
    "    new_list = []\n",
    "    for x in range(len(sub_array_indices)-1):\n",
    "        new_list.append(old_list[sub_array_indices[x] : sub_array_indices[x+1]])\n",
    "    return new_list\n",
    "\n",
    "\n",
    "def get_data(filepath): \n",
    "    parameters = get_params(filepath)\n",
    "    names, values = [], []\n",
    "    j_protocols, k_protocols, b_protocols  = [], [],[]\n",
    "    tau_array, best_E_array, total_steps_array, time_step_array, distance_array, best_E_fixed_tau_array  = [],[],[],[],[],[]\n",
    "    \n",
    "    for line in open(filepath, \"rt\"):     \n",
    "        line = line.rstrip(\"\\n\")\n",
    "        if line.startswith('tau'): tau_array.append(float((line.split('=')[-1]).replace(\" \", \"\")))\n",
    "        elif line.startswith('best_E_fixed_tau'): best_E_fixed_tau_array.append(literal_eval((line.split('=')[-1]).replace(\" \", \"\")))\n",
    "        elif line.startswith('best_E'): best_E_array.append(float((line.split('=')[-1]).replace(\" \", \"\")))\n",
    "        elif line.startswith('distance'): distance_array.append(float((line.split('=')[-1]).replace(\" \", \"\")))\n",
    "        elif line.startswith('j_protocol'): j_protocols.append(literal_eval((line.split('=')[-1]).replace(\" \", \"\")))\n",
    "        elif line.startswith('k_protocol'): k_protocols.append(literal_eval((line.split('=')[-1]).replace(\" \", \"\")))\n",
    "        elif line.startswith('b_protocol'): b_protocols.append(literal_eval((line.split('=')[-1]).replace(\" \", \"\")))\n",
    "        elif line.startswith('total_steps'): total_steps_array.append(int((line.split('=')[-1]).replace(\" \", \"\")))\n",
    "        elif line.startswith('time_step'): time_step_array.append(float((line.split('=')[-1]).replace(\" \", \"\")))\n",
    "\n",
    "    potential_names = ['parameters', 'j_protocols','k_protocols','b_protocols',\n",
    "                       'tau_array', 'best_E_array', 'distance_array', \n",
    "                       'best_E_fixed_tau_array','total_steps_array', 'time_step_array']\n",
    "    potential_values = [parameters, j_protocols, k_protocols, b_protocols,\n",
    "                        tau_array, best_E_array, distance_array,\n",
    "                        best_E_fixed_tau_array, total_steps_array, time_step_array]\n",
    "    for x in range(len(potential_values)):\n",
    "        if (len(potential_values[x]) == 0): continue\n",
    "        names.append(potential_names[x])\n",
    "        values.append(potential_values[x])\n",
    "    return [names, values]\n",
    "\n",
    "\n",
    "def find_optimal_seeds(data_mcbb_whole,data_mcdb_whole, data_mcbf_whole):\n",
    "\n",
    "    for data_mcbb in data_mcbb_whole[1]:\n",
    "        best_E_fixed_tau_array = get_values(data_mcbb, \"best_E_fixed_tau_array\")\n",
    "\n",
    "        j_protocols = get_values(data_mcbb, \"j_protocols\")\n",
    "        k_protocols = get_values(data_mcbb, \"k_protocols\")\n",
    "        b_protocols = get_values(data_mcbb, \"b_protocols\")\n",
    "        tau_array = get_values(data_mcbb, \"tau_array\")\n",
    "        best_E_array = get_values(data_mcbb, \"best_E_array\")\n",
    "        distance_array = get_values(data_mcbb, \"distance_array\")\n",
    "\n",
    "        for x in range(len(best_E_fixed_tau_array)):\n",
    "            best_E_index = best_E_fixed_tau_array[x].index(min(best_E_fixed_tau_array[x]))\n",
    "            j_protocols[x] = j_protocols[x][best_E_index]\n",
    "            k_protocols[x] = k_protocols[x][best_E_index]\n",
    "            b_protocols[x] = b_protocols[x][best_E_index]\n",
    "        remove_index = data_mcbb[0].index('best_E_fixed_tau_array')  \n",
    "        data_mcbb[0].pop(remove_index)\n",
    "        data_mcbb[1].pop(remove_index)\n",
    "\n",
    "       \n",
    "    for data_mcbf in data_mcbf_whole[1]:\n",
    "\n",
    "        best_E_fixed_tau_array = get_values(data_mcbf, \"best_E_fixed_tau_array\")\n",
    "\n",
    "        j_protocols = get_values(data_mcbf, \"j_protocols\")\n",
    "        k_protocols = get_values(data_mcbf, \"k_protocols\")\n",
    "        b_protocols = get_values(data_mcbf, \"b_protocols\")\n",
    "        \n",
    "        for x in range(len(best_E_fixed_tau_array)):\n",
    "            best_E_index = best_E_fixed_tau_array[x].index(min(best_E_fixed_tau_array[x]))\n",
    "            j_protocols[x] = j_protocols[x][best_E_index]\n",
    "            k_protocols[x] = k_protocols[x][best_E_index]\n",
    "            b_protocols[x] = b_protocols[x][best_E_index]\n",
    "        remove_index = data_mcbf[0].index('best_E_fixed_tau_array')  \n",
    "        data_mcbf[0].pop(remove_index)\n",
    "        data_mcbf[1].pop(remove_index)\n",
    "        \n",
    "    for data_mcdb in data_mcdb_whole[1]:\n",
    "\n",
    "        best_E_fixed_tau_array = get_values(data_mcdb, \"best_E_fixed_tau_array\")\n",
    "\n",
    "        j_protocols = get_values(data_mcdb, \"j_protocols\")\n",
    "        k_protocols = get_values(data_mcdb, \"k_protocols\")\n",
    "        b_protocols = get_values(data_mcdb, \"b_protocols\")\n",
    "        \n",
    "        for x in range(len(best_E_fixed_tau_array)):\n",
    "            best_E_index = best_E_fixed_tau_array[x].index(min(best_E_fixed_tau_array[x]))\n",
    "            j_protocols[x] = j_protocols[x][best_E_index]\n",
    "            k_protocols[x] = k_protocols[x][best_E_index]\n",
    "            b_protocols[x] = b_protocols[x][best_E_index]\n",
    "        remove_index = data_mcdb[0].index('best_E_fixed_tau_array')  \n",
    "        data_mcdb[0].pop(remove_index)\n",
    "        data_mcdb[1].pop(remove_index)\n",
    "        \n",
    "        \n",
    "        \n",
    "def index_containing_substring(the_list, substring1, substring2):\n",
    "    for i, s in enumerate(the_list):\n",
    "        if substring1 in s and substring2 in s:\n",
    "              return i\n",
    "    return -1\n",
    "\n",
    "\n",
    "def remove_non_monotonic_behavior(data_mcbb_whole,data_mcdb_whole, data_mcbf_whole):\n",
    "    for data_whole in [data_mcbb_whole,data_mcdb_whole, data_mcbf_whole]:\n",
    "        for data in data_whole[1]:\n",
    "            array_collection = [get_values(data, \"j_protocols\"),get_values(data, \"k_protocols\"),\n",
    "                                get_values(data, \"b_protocols\"),get_values(data, \"tau_array\"),\n",
    "                                get_values(data, \"best_E_array\"), get_values(data, \"distance_array\")]\n",
    "            if(data_whole == data_mcbf_whole):\n",
    "                array_collection.append(get_values(data, \"total_steps_array\"))\n",
    "                array_collection.append(get_values(data, \"time_step_array\"))\n",
    "        \n",
    "            best_E_array = get_values(data, \"best_E_array\")\n",
    "\n",
    "            size = len(best_E_array)\n",
    "            x=0\n",
    "            while(x<size):\n",
    "                lowest_E = best_E_array[x]\n",
    "                y=x+1\n",
    "                while(y<size):\n",
    "                    if(best_E_array[y] > lowest_E):\n",
    "                        for array in array_collection:\n",
    "                            array.pop(y)\n",
    "                        size-=1\n",
    "                    y+=1\n",
    "                x+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all_data(data_mcbb_whole, data_mcdb_whole,data_mcbf_whole, data_adia_whole):\n",
    "    reduce_time_array(data_mcbb_whole, data_mcdb_whole)\n",
    "    extrapolate_pre_convergence_time(data_mcbb_whole)\n",
    "    extrapolate_pre_convergence_time(data_mcdb_whole)\n",
    "    calc_num_jumps(data_mcbb_whole)\n",
    "    calc_num_jumps(data_mcdb_whole)\n",
    "    calc_characteristic_times(data_mcbb_whole)\n",
    "    calc_characteristic_times(data_mcdb_whole)\n",
    "          \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def reduce_time_array(data_mcbb_whole, data_mcdb_whole):\n",
    "\n",
    "    for data_mcbb in data_mcbb_whole[1]:\n",
    "        j_protocols, k_protocols, b_protocols = get_values(data_mcbb, \"j_protocols\"), get_values(data_mcbb, \"k_protocols\"), get_values(data_mcbb, \"b_protocols\")\n",
    "        j_protocols_reduced, k_protocols_reduced, b_protocols_reduced = [], [], []\n",
    "\n",
    "        old_lists = [j_protocols,k_protocols, b_protocols]\n",
    "        new_lists = [j_protocols_reduced,k_protocols_reduced,b_protocols_reduced]\n",
    "        new_list_names = ['j_protocols_reduced', 'k_protocols_reduced','b_protocols_reduced']    \n",
    "\n",
    "        for x in range(len(old_lists)): #iterate over lists     \n",
    "            reduced_times = []\n",
    "            for y in range(len(old_lists[x])): #iterate over each tau\n",
    "                \n",
    "        \n",
    "                old_protocol = (old_lists[x][y]).copy()\n",
    "                collapse_limit = (old_protocol[-1] - old_protocol[0])*COLLAPSE_LIMIT_FRACTION\n",
    "                \n",
    "                index=0\n",
    "                max_loops = len(old_protocol)\n",
    "\n",
    "                while(index<max_loops-1):\n",
    "                    if(abs(old_protocol[index]-old_protocol[index+1]) < collapse_limit):\n",
    "                        del old_protocol[index+1]\n",
    "                        del old_protocol[index]\n",
    "                        max_loops -= 2\n",
    "                    else: index += 1  \n",
    "\n",
    "                reduced_times.append(old_protocol)\n",
    "\n",
    "            data_mcbb[1].append(reduced_times)\n",
    "            data_mcbb[0].append(new_list_names[x])\n",
    "    \n",
    "    for data_mcdb in data_mcdb_whole[1]:\n",
    "        time_step = get_values(data_mcdb, \"time_step_array\")[-1]\n",
    "        tau_array = get_values(data_mcdb, \"tau_array\")\n",
    "        j_protocols, k_protocols, b_protocols = get_values(data_mcdb, \"j_protocols\"), get_values(data_mcdb, \"k_protocols\"), get_values(data_mcdb, \"b_protocols\")\n",
    "        j_protocols_reduced, k_protocols_reduced, b_protocols_reduced = [], [], []\n",
    "\n",
    "        old_lists = [j_protocols,k_protocols, b_protocols]\n",
    "        new_lists = [j_protocols_reduced,k_protocols_reduced,b_protocols_reduced]\n",
    "        new_list_names = ['j_protocols_reduced', 'k_protocols_reduced','b_protocols_reduced']    \n",
    "\n",
    "        for x in range(len(old_lists)): #iterate over lists     \n",
    "            reduced_times = []\n",
    "            for y in range(len(old_lists[x])): #iterate over each tau\n",
    "                \n",
    "                converted_protocol = []\n",
    "                if(old_lists[x][y][0] == 1): converted_protocol.append(0)\n",
    "                for z in range(len(old_lists[x][y])-1): \n",
    "                    if(old_lists[x][y][z] != old_lists[x][y][z+1]): converted_protocol.append(time_step*(z+1))\n",
    "                converted_protocol.append(tau_array[y])\n",
    "                \n",
    "                #print(\"before:\", converted_protocol, \"\\n\")\n",
    "                collapse_limit = tau_array[y]*COLLAPSE_LIMIT_FRACTION                \n",
    "                index=0\n",
    "                max_loops = len(converted_protocol)\n",
    "\n",
    "                while(index<max_loops-1):\n",
    "                    if(abs(converted_protocol[index]-converted_protocol[index+1]) < collapse_limit):\n",
    "                        del converted_protocol[index+1]\n",
    "                        del converted_protocol[index]\n",
    "                        max_loops -= 2\n",
    "                    else: index += 1  \n",
    "                        \n",
    "                        \n",
    "                if(tau_array[y] not in converted_protocol):  converted_protocol.append(tau_array[y])\n",
    "                #print(\"after:\", converted_protocol, \"\\n\\n\\n\\n\")\n",
    "\n",
    "                reduced_times.append(converted_protocol)\n",
    "\n",
    "            data_mcdb[1].append(reduced_times)\n",
    "            data_mcdb[0].append(new_list_names[x])  \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "def extrapolate_pre_convergence_time(data_mcbb_whole):\n",
    "    \n",
    "    for data,file in zip(data_mcbb_whole[1], data_mcbb_whole[0]):\n",
    "        ground_E = float(get_values(get_values(data, \"parameters\"), \"GROUND_E\"))\n",
    "        initial_E = float(get_values(get_values(data, \"parameters\"), \"INITIAL_E\"))\n",
    "        if(ground_E == initial_E): continue\n",
    "        tau_array = get_values(data, \"tau_array\")\n",
    "        best_E_array = get_values(data, \"best_E_array\")\n",
    "        j_protocols_reduced = get_values(data, \"j_protocols_reduced\")\n",
    "        k_protocols_reduced = get_values(data, \"k_protocols_reduced\")\n",
    "        b_protocols_reduced = get_values(data, \"b_protocols_reduced\")\n",
    "\n",
    "        j_protocols_extrapolated, k_protocols_extrapolated, b_protocols_extrapolated, taus_extrapolated = [], [], [], []\n",
    "        j_coeffs, k_coeffs, b_coeffs = [], [], []\n",
    "        j_index, k_index, b_index = [], [], []\n",
    "\n",
    "        distance_array = [(best_E-ground_E)/(initial_E-ground_E) for best_E in best_E_array]\n",
    "        point_within_dist_lim = np.where(np.array(distance_array) < DISTANCE_LIMIT)[0]   \n",
    "\n",
    "        if (len(point_within_dist_lim) > 1):\n",
    "\n",
    "            taus = np.array(tau_array)[point_within_dist_lim]\n",
    "            best_Es = np.array(best_E_array)[point_within_dist_lim]\n",
    "            tau_line = np.poly1d(np.polyfit(best_Es, taus,1))\n",
    "            #tau_line = np.poly1d([linear_fit_through_0(best_Es, taus), 0])\n",
    "            extrapolated_tau= max(tau_line(ground_E), taus[-1])\n",
    "            js_reduced = list(np.array(j_protocols_reduced)[point_within_dist_lim])\n",
    "            ks_reduced = list(np.array(k_protocols_reduced)[point_within_dist_lim])\n",
    "\n",
    "            size_j, size_k= len(js_reduced[-1]),len(js_reduced[-1]) #getting the number of jumps in the last of the 'best' protocols\n",
    "\n",
    "            for y in range(len(point_within_dist_lim)):\n",
    "                if (len(js_reduced[y]) == size_j):j_index.append(y)\n",
    "                if (len(ks_reduced[y]) == size_k):k_index.append(y)\n",
    "\n",
    "            js_reduced2, ks_reduced2, = [], []\n",
    "            for y in range(len(j_index)): js_reduced2.append(js_reduced[j_index[y]])\n",
    "            for y in range(len(k_index)): ks_reduced2.append(ks_reduced[k_index[y]])\n",
    "\n",
    "            js_reduced = np.array([np.array(xi) for xi in js_reduced2]).T\n",
    "            ks_reduced = np.array([np.array(xi) for xi in ks_reduced2]).T\n",
    "            \n",
    "            \n",
    "        \n",
    "            if(len(j_index) > 2):\n",
    "                for y in range(len(js_reduced)):\n",
    "                    j_coefficient = linear_fit_through_0(taus[j_index],js_reduced[y])\n",
    "                    j_coeffs.append(j_coefficient)\n",
    "                    j_line = np.poly1d([j_coefficient,0])\n",
    "                    interpolated_j = j_line(extrapolated_tau)\n",
    "\n",
    "                    if(interpolated_j <= 0):  j_protocols_extrapolated.append(0)\n",
    "                    elif(interpolated_j >= extrapolated_tau): j_protocols_extrapolated.append(extrapolated_tau)\n",
    "                    elif((y > 0) and (interpolated_j < j_protocols_extrapolated[-1])): j_protocols_extrapolated.append(j_protocols_extrapolated[-1])\n",
    "                    else: j_protocols_extrapolated.append(interpolated_j)\n",
    "\n",
    "            else: \n",
    "                j_protocols_extrapolated.extend(j_protocols_reduced[-1])\n",
    "                j_coeffs.append(0)\n",
    "\n",
    "            if(len(k_index) > 2):\n",
    "                for y in range(len(ks_reduced)):\n",
    "                    k_coefficient = linear_fit_through_0(taus[k_index],ks_reduced[y])\n",
    "                    #k_coefficients = np.polyfit(taus[k_index],ks_reduced_per_seed[y], 1)\n",
    "                    k_coeffs.append(k_coefficient)\n",
    "                    k_line = np.poly1d([k_coefficient,0])\n",
    "                    interpolated_k = k_line(extrapolated_tau)\n",
    "\n",
    "                    if(interpolated_k <= 0):  k_protocols_extrapolated.append(0)\n",
    "                    elif(interpolated_k >= taus[-1]): k_protocols_extrapolated.append(taus[-1])\n",
    "                    elif((y > 0) and (interpolated_k < k_protocols_extrapolated[-1])): k_protocols_extrapolated.append(k_protocols_extrapolated[-1])\n",
    "                    else: k_protocols_extrapolated.append(interpolated_k)\n",
    "\n",
    "            else: \n",
    "                k_protocols_extrapolated.extend(k_protocols_reduced[-1])\n",
    "                k_coeffs.append(0)\n",
    "\n",
    "        else:\n",
    "            j_protocols_extrapolated.extend(j_protocols_reduced[-1])\n",
    "            k_protocols_extrapolated.extend(k_protocols_reduced[-1])\n",
    "            j_coeffs.append(0)\n",
    "            k_coeffs.append(0)\n",
    "\n",
    "        \n",
    "        data[0].append('tau_extrapolated')\n",
    "        data[1].append(extrapolated_tau)\n",
    "        data[0].append('j_protocols_extrapolated')\n",
    "        data[1].append(j_protocols_extrapolated)\n",
    "        data[0].append('k_protocols_extrapolated')\n",
    "        data[1].append(k_protocols_extrapolated)\n",
    "        data[0].append('j_coeffs')\n",
    "        data[1].append(j_coeffs)\n",
    "        data[0].append('k_coeffs')\n",
    "        data[1].append(k_coeffs)\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "            \n",
    "def linear_fit_through_0(x, y):\n",
    "    return np.linalg.lstsq(x.reshape(-1,1), y, rcond=None)[0][0]\n",
    "            \n",
    "            \n",
    "        \n",
    "def calc_num_jumps(data_mcbb_whole):  \n",
    "    \n",
    "    for data,file in zip(data_mcbb_whole[1], data_mcbb_whole[0]):\n",
    "\n",
    "        j_protocols_reduced, k_protocols_reduced, b_protocols_reduced = get_values(data, \"j_protocols_reduced\"), get_values(data, \"k_protocols_reduced\"), get_values(data, \"b_protocols_reduced\")\n",
    "        old_lists = [j_protocols_reduced,k_protocols_reduced, b_protocols_reduced]\n",
    "        new_list_names = ['j_jumps', 'k_jumps','b_jumps']    \n",
    "        \n",
    "\n",
    "        for x in range(len(old_lists)): #iterate over lists\n",
    "            jumps = []\n",
    "            if(len(old_lists[x]) == 1): jumps.append(0)\n",
    "            else:\n",
    "                for y in range(len(old_lists[x])): #iterate over each tau\n",
    "                    jump = len(old_lists[x][y])-1\n",
    "                    jumps.append(jump)                \n",
    "            data[0].append(new_list_names[x])\n",
    "            data[1].append(jumps)\n",
    "            \n",
    "            \n",
    "        \n",
    "def calc_characteristic_times(data_mcbb_whole):  \n",
    "    \n",
    "    for data,file in zip(data_mcbb_whole[1], data_mcbb_whole[0]):\n",
    "\n",
    "        j_protocols_reduced, k_protocols_reduced, b_protocols_reduced = get_values(data, \"j_protocols_reduced\")[-1], get_values(data, \"k_protocols_reduced\")[-1], get_values(data, \"b_protocols_reduced\")[-1]\n",
    "        tau = get_values(data, \"tau_array\")[-1]\n",
    "        if(tau == 0): tau = 1\n",
    "        old_lists = [j_protocols_reduced.copy(),k_protocols_reduced.copy(), b_protocols_reduced.copy()]\n",
    "        new_list_names = ['j_char_time', 'j_char_time_over_tau', 'k_char_time','k_char_time_over_tau', 'b_char_time','b_char_time_over_tau', ]    \n",
    "        #GET CHAR TIME OVER TAU TOO\n",
    "\n",
    "        for x in range(len(old_lists)): #iterate over lists\n",
    "            char_time = []\n",
    "            if(len(old_lists[x]) == 1):\n",
    "                print(old_lists[x])\n",
    "                if(old_lists[x][0] == tau): char_time = [0,tau]\n",
    "                elif(old_lists[x][0] == 0): char_time = [tau,0]\n",
    "                else:char_time = [0,0]\n",
    "            else:\n",
    "                old_lists[x].insert(0,0)\n",
    "                old_lists[x].append(tau)\n",
    "                for y in range(len(old_lists[x]) - 1): #iterate over each tau\n",
    "                    char_time.append(old_lists[x][y+1]-old_lists[x][y])\n",
    "                    \n",
    "                num_1s = 0\n",
    "                char_1 = 0\n",
    "                char_0 = 0\n",
    "                num_0s = 0\n",
    "\n",
    "                for y in range(len(char_time)):\n",
    "                    if(y%2 == 0):\n",
    "                        char_0 += char_time[y]\n",
    "                        if(char_time[y] > 0.000001): num_0s += 1\n",
    "                    else:\n",
    "                        char_1 += char_time[y]\n",
    "                        if(char_time[y] > 0.000001): num_1s += 1\n",
    "                        \n",
    "                if(num_1s > 0): char_1 = char_1/num_1s\n",
    "                else: char_1 = 0\n",
    "                    \n",
    "                if(num_1s > 0): char_1 = char_1/num_1s\n",
    "                else: char_0 = 0\n",
    "                char_time = [char_1, char_0]\n",
    "            \n",
    "            \n",
    "            \n",
    "            data[0].append(new_list_names[2*x])\n",
    "            data[0].append(new_list_names[2*x+1])\n",
    "            data[1].append(char_time)\n",
    "            data[1].append([i/tau for i in char_time])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-5-0b42ff9b68ce>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-0b42ff9b68ce>\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    def step_plot(x, y, title, x_label,color, y_label, x_upper, x_lower, y_upper, y_lower):\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def plot_data(data_mcbb_whole,data_mcbf_whole,data_adia_whole, save):\n",
    "#     mcbb_group_plot(data_mcbb_whole,save)\n",
    "#     plot_E_vs_tau(data_mcbb_whole,data_mcbf_whole,data_adia_whole,save)\n",
    "#     plot_jump_vs_tau(data_mcbb_whole,save)\n",
    "#     plot_jkb_best_mcbb(data_mcbb_whole,save)\n",
    "#     plot_jkb_best_mcbf(data_mcbf_whole,save)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def step_plot(x, y, title, x_label,color, y_label, x_upper, x_lower, y_upper, y_lower):\n",
    "    plt.title(title)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    plt.ylim(y_lower, y_upper)\n",
    "    plt.step(x,y, c=color)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "def plot_E_vs_tau(data_mcbb_whole,data_mcbf_whole,data_adia_whole,save):\n",
    "    \n",
    "    for x in range(len(data_mcbb_whole[1])):\n",
    "        \n",
    "        data_mcbb = data_mcbb_whole[1][x]\n",
    "        unique_params = ((data_mcbb_whole[0][x]).split(\"MCBB___\")[1]).split(\".txt\")[0]\n",
    "        lattice_params = (data_mcbb_whole[0][x].split(\"data/\")[1]).split(\"\\\\\")[0]\n",
    "       \n",
    "        ground_E = float(get_values(get_values(data_mcbb, \"parameters\"), \"GROUND_E\"))\n",
    "        initial_E = float(get_values(get_values(data_mcbb, \"parameters\"), \"INITIAL_E\"))\n",
    "        if(ground_E == initial_E): continue\n",
    "        taus_mcbb, Es_mcbb, = get_values(data_mcbb, \"tau_array\").copy(), get_values(data_mcbb, \"best_E_array\").copy()\n",
    "        taus_mcbb.insert(0,0), Es_mcbb.insert(0, initial_E)\n",
    "        \n",
    "        x_upper = taus_mcbb[-1]*1.01\n",
    "        x_lower = 0\n",
    "        y_upper = initial_E + abs(initial_E - ground_E) *0.01\n",
    "        y_lower = ground_E  - abs(initial_E - ground_E) *0.01\n",
    "        fig = plt.figure(figsize=(15,11))\n",
    "        ground_E_line  = np.full(np.size(taus_mcbb), ground_E)\n",
    "        ground_label = 'Ground_E: {0:.3f}'.format(ground_E)\n",
    "\n",
    "        title = \"Energy_vs_Tau___\" + unique_params\n",
    "        plt.ylabel(\"Best Energy Post-MC\")\n",
    "        plt.xlabel(\"Total Time for MC\")\n",
    "        plt.title(title)\n",
    "        plt.xlim(x_lower, x_upper)\n",
    "        plt.ylim(y_lower, y_upper)\n",
    "        plt.plot(taus_mcbb, Es_mcbb,label='MCBB', lw=4, c='red')\n",
    "        plt.plot(taus_mcbb, ground_E_line,label=ground_label, lw=5, c='black')\n",
    "        #plt.scatter(adasdasfasd)\n",
    "\n",
    "        \n",
    "        mcbf_index = index_containing_substring(data_mcbf_whole[0],unique_params, lattice_params)\n",
    "        if(mcbf_index >= 0):\n",
    "            data_mcbf = data_mcbf_whole[1][mcbf_index]\n",
    "            taus_mcbf, Es_mcbf, = get_values(data_mcbf, \"tau_array\").copy(), get_values(data_mcbf, \"best_E_array\").copy()\n",
    "            taus_mcbf.insert(0,0), Es_mcbf.insert(0, initial_E)\n",
    "            plt.plot(taus_mcbf, Es_mcbf,label='MCBF', lw=4, c='green')  \n",
    "            \n",
    "            \n",
    "        mcdb_index = index_containing_substring(data_mcdb_whole[0],unique_params, lattice_params)\n",
    "        if(mcdb_index >= 0):\n",
    "            data_mcdb = data_mcdb_whole[1][mcdb_index]\n",
    "            taus_mcdb, Es_mcdb, = get_values(data_mcdb, \"tau_array\").copy(), get_values(data_mcdb, \"best_E_array\").copy()\n",
    "            taus_mcdb.insert(0,0), Es_mcdb.insert(0, initial_E)\n",
    "            plt.plot(taus_mcdb, Es_mcdb,label='MCDB', lw=4, c='blue')       \n",
    "        \n",
    "        \n",
    "        adia_index = index_containing_substring(data_adia_whole[0],unique_params, lattice_params)\n",
    "        if(adia_index >= 0):\n",
    "            data_adia = data_adia_whole[1][adia_index]\n",
    "            taus_adia, Es_adia, = get_values(data_adia, \"tau_array\").copy(), get_values(data_adia, \"best_E_array\").copy()\n",
    "            taus_adia.insert(0,0), Es_adia.insert(0, initial_E)\n",
    "            plt.plot(taus_adia, Es_adia,label='ADIA', lw=4, c='orange')  \n",
    "            \n",
    "        plt.legend()\n",
    "\n",
    "        \n",
    "        if(save):\n",
    "            dir = \"figures/\" + lattice_params\n",
    "            if not os.path.exists(dir): os.makedirs(dir) \n",
    "            plt.savefig(dir_ + \"/\" + unique_params.replace(\"/\", \"_\") + \"_E_vs_tau.pdf\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def plot_jkb_best_mcbb(data_mcbb_whole,save): \n",
    "    for (data_mcbb, file_name) in zip(data_mcbb_whole[1], data_mcbb_whole[0]):\n",
    "        \n",
    "        ground_E = float(get_values(get_values(data_mcbb, \"parameters\"), \"GROUND_E\"))\n",
    "        initial_E = float(get_values(get_values(data_mcbb, \"parameters\"), \"INITIAL_E\"))  \n",
    "        if(ground_E == initial_E): continue\n",
    "\n",
    "        unique_params = (file_name.split(\"MCBB___\")[1]).split(\".txt\")[0]\n",
    "        lattice_params = (file_name.split(\"data/\")[1]).split(\"\\\\\")[0]\n",
    "        \n",
    "        mcbb_tau = (get_values(data_mcbb, \"tau_array\"))[-1]\n",
    "\n",
    "        j_protocols_reduced = (get_values(data_mcbb, \"j_protocols_reduced\")[-1]).copy()\n",
    "        j_protocols_reduced.insert(0,0), j_protocols_reduced.append(mcbb_tau)\n",
    "\n",
    "        k_protocols_reduced = (get_values(data_mcbb, \"k_protocols_reduced\")[-1]).copy()\n",
    "        k_protocols_reduced.append(mcbb_tau), k_protocols_reduced.insert(0,0)\n",
    "\n",
    "        jkb_vals = [1,0,1,0,1,0,1,0,1,0,1,0,1,0]\n",
    "\n",
    "\n",
    "        fig = plt.figure(figsize=(14,4))\n",
    "        title = \"MCBB Best Jumps vs Time \" + unique_params\n",
    "        fig.suptitle(title)\n",
    "        plt.subplot(\"121\")\n",
    "        step_plot(j_protocols_reduced, jkb_vals[:np.size(j_protocols_reduced)], '', \"Time\",'blue' ,'J', mcbb_tau, 0, 1.1, -.1)\n",
    "\n",
    "        plt.subplot(\"122\")\n",
    "        step_plot(k_protocols_reduced, jkb_vals[:np.size(k_protocols_reduced)], '', \"Time\",'limegreen' ,'K', mcbb_tau, 0, 1.1, -.1)\n",
    "\n",
    "        \n",
    "        if(save):\n",
    "            dir = \"figures/\" + lattice_params\n",
    "            if not os.path.exists(dir): os.makedirs(dir) \n",
    "            plt.savefig(dir_ + \"/\" + unique_params.replace(\"/\", \"_\") + \"_best_protocols_mcbb.pdf\")\n",
    "        plt.show()  \n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "def plot_jkb_best_mcbf(data_mcbf_whole,save): \n",
    "    \n",
    "    for (data_mcbf, file_name) in zip(data_mcbf_whole[1], data_mcbf_whole[0]):\n",
    "             \n",
    "        unique_params = (file_name.split(\"MCBF___\")[1]).split(\".txt\")[0]\n",
    "        lattice_params = (file_name.split(\"data/\")[1]).split(\"\\\\\")[0]\n",
    "        \n",
    "        mcbf_tau = (get_values(data_mcbf, \"tau_array\"))[-1]\n",
    "\n",
    "        j_protocols = get_values(data_mcbf, \"j_protocols\")[:]\n",
    "        k_protocols = get_values(data_mcbf, \"k_protocols\")[:]\n",
    "        total_steps = get_values(data_mcbf, \"total_steps_array\")[-1]\n",
    "        j_best = j_protocols[-1]\n",
    "        k_best = k_protocols[-1]\n",
    "        times = np.linspace(0,mcbf_tau, total_steps)\n",
    "\n",
    "\n",
    "        fig = plt.figure(figsize=(14,4))\n",
    "        title = \"MCBF Best Jumps vs Time\"\n",
    "        fig.suptitle(title)\n",
    "        plt.subplot(\"121\")\n",
    "        step_plot(times, j_best, '', \"Time\",'blue' ,'J', mcbf_tau, 0, 1.1, -.1)\n",
    "\n",
    "        plt.subplot(\"122\")\n",
    "        step_plot(times, k_best, '', \"Time\",'limegreen' ,'K', mcbf_tau, 0, 1.1, -.1)\n",
    " \n",
    "        if(save):\n",
    "            dir = \"figures/\" + lattice_params\n",
    "            if not os.path.exists(dir): os.makedirs(dir) \n",
    "            plt.savefig(dir_ + \"/\" + unique_params.replace(\"/\", \"_\") + \"_best_protocols_mcbf.pdf\")\n",
    "        plt.show()  \n",
    "\n",
    "    \n",
    "    \n",
    "def plot_jump_vs_tau(data_mcbb_whole,save): \n",
    "    for (data_mcbb, file_name) in zip(data_mcbb_whole[1], data_mcbb_whole[0]):\n",
    "        \n",
    "        unique_params = (file_name.split(\"MCBB___\")[1]).split(\".txt\")[0]\n",
    "        lattice_params = (file_name.split(\"data/\")[1]).split(\"MCBB\")[0]\n",
    "        \n",
    "        ground_E = float(get_values(get_values(data_mcbb, \"parameters\"), \"GROUND_E\"))\n",
    "        initial_E = float(get_values(get_values(data_mcbb, \"parameters\"), \"INITIAL_E\"))  \n",
    "        if(ground_E == initial_E): continue\n",
    "            \n",
    "        j_protocols_reduced = get_values(data_mcbb, \"j_protocols_reduced\")\n",
    "        k_protocols_reduced = get_values(data_mcbb, \"k_protocols_reduced\")\n",
    "        j_coeffs = get_values(data_mcbb, \"j_coeffs\")\n",
    "        k_coeffs = get_values(data_mcbb, \"k_coeffs\")\n",
    "        tau_array = get_values(data_mcbb, \"tau_array\")\n",
    "\n",
    "        plt.figure()\n",
    "        title = \"Jumps vs Tau\"\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Tau\")\n",
    "        plt.ylabel(\"Time of Jump\")\n",
    " \n",
    "        for x in range(len(j_protocols_reduced)):\n",
    "            plt.scatter(np.full(np.size(j_protocols_reduced[x]),tau_array[x]), j_protocols_reduced[x], c='blue',s=20)\n",
    "        for x in range(len(k_protocols_reduced)):\n",
    "            plt.scatter(np.full(np.size(k_protocols_reduced[x]),tau_array[x]), k_protocols_reduced[x], c='green' ,s=20)\n",
    "        plt.plot(tau_array, tau_array, c = 'black')\n",
    "        plt.plot(tau_array, np.linspace(0,0,len(tau_array)), c = 'black')\n",
    "        plt.plot(0,0,c='blue', label = 'j')\n",
    "        plt.plot(0,0,c='limegreen', label = 'k')\n",
    "        plt.legend()\n",
    "\n",
    "        if(save):\n",
    "            dir = 'figures/' + lattice_params\n",
    "            if not os.path.exists(dir): os.makedirs(dir)  \n",
    "            plt.savefig(dir + \"/\" + lattice_params.replace(\"/\", \"_\") + \"_jump_vs_tau.pdf\")\n",
    "        plt.show()  \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "def mcbb_group_plot(data_mcbb_whole, save):   \n",
    "    \n",
    "    for (data_mcbb, file_name) in zip(data_mcbb_whole[1], data_mcbb_whole[0]):\n",
    "        \n",
    "        ground_E = float(get_values(get_values(data_mcbb, \"parameters\"), \"GROUND_E\"))\n",
    "        initial_E = float(get_values(get_values(data_mcbb, \"parameters\"), \"INITIAL_E\"))  \n",
    "        if(ground_E == initial_E): continue\n",
    "\n",
    "        unique_params = (file_name.split(\"MCBB___\")[1]).split(\".txt\")[0]\n",
    "        lattice_params = (file_name.split(\"data/\")[1]).split(\"MCBB\")[0]\n",
    "        \n",
    "        mcbb_tau = (get_values(data_mcbb, \"tau_array\"))[-1]\n",
    "\n",
    "        \n",
    "        \n",
    "        fig = plt.figure(figsize=(20,14))\n",
    "        fig.suptitle(unique_params)        \n",
    "           \n",
    "        plt.subplot(\"223\")\n",
    "        j_protocols_reduced = (get_values(data_mcbb, \"j_protocols_reduced\")[-1]).copy()\n",
    "        j_protocols_reduced.insert(0,0), j_protocols_reduced.append(mcbb_tau)\n",
    "        jkb_vals = [1,0,1,0,1,0,1,0,1,0,1,0,1,0]\n",
    "        step_plot(j_protocols_reduced, jkb_vals[:np.size(j_protocols_reduced)], '', \"Time\",'blue' ,'J', mcbb_tau, 0, 1.1, -.1)\n",
    "        plt.subplot(\"224\")\n",
    "        k_protocols_reduced = (get_values(data_mcbb, \"k_protocols_reduced\")[-1]).copy()\n",
    "        k_protocols_reduced.append(mcbb_tau), k_protocols_reduced.insert(0,0)\n",
    "        step_plot(k_protocols_reduced, jkb_vals[:np.size(k_protocols_reduced)], '', \"Time\",'limegreen' ,'K', mcbb_tau, 0, 1.1, -.1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        plt.subplot(\"222\")\n",
    "        j_protocols_reduced,k_protocols_reduced = get_values(data_mcbb, \"j_protocols_reduced\"),get_values(data_mcbb, \"k_protocols_reduced\")\n",
    "        j_coeffs,k_coeffs = get_values(data_mcbb, \"j_coeffs\"),get_values(data_mcbb, \"k_coeffs\")\n",
    "        tau_array = get_values(data_mcbb, \"tau_array\")\n",
    "        for x in range(len(j_protocols_reduced)): plt.scatter(np.full(np.size(j_protocols_reduced[x]),tau_array[x]), j_protocols_reduced[x], c='blue',s=20)\n",
    "        for x in range(len(k_protocols_reduced)): plt.scatter(np.full(np.size(k_protocols_reduced[x]),tau_array[x]), k_protocols_reduced[x], c='green' ,s=20)\n",
    "        plt.plot(tau_array, tau_array, c = 'black')\n",
    "        plt.plot(tau_array, np.linspace(0,0,len(tau_array)), c = 'black')\n",
    "        plt.plot(0,0,c='blue', label = 'j')\n",
    "        plt.plot(0,0,c='limegreen', label = 'k')\n",
    "        plt.legend()\n",
    "        \n",
    " \n",
    "\n",
    "        plt.subplot(\"221\")\n",
    "        taus_mcbb, Es_mcbb, = get_values(data_mcbb, \"tau_array\").copy(), get_values(data_mcbb, \"best_E_array\").copy()\n",
    "        taus_mcbb.insert(0,0), Es_mcbb.insert(0, initial_E)\n",
    "        j_jumps, k_jumps = get_values(data_mcbb, \"j_jumps\"), get_values(data_mcbb, \"k_jumps\")\n",
    "        j_change, k_change = -1, -1\n",
    "        for x in range(len(j_jumps)-1): \n",
    "            if(j_jumps[x] != j_jumps[x+1]):\n",
    "                j_change = x\n",
    "                break\n",
    "        for x in range(len(k_jumps)-1):\n",
    "            if(k_jumps[x] != k_jumps[x+1]):\n",
    "                k_change = x\n",
    "                break\n",
    "        ground_E_line  = np.full(np.size(taus_mcbb), ground_E)\n",
    "        ground_label = 'Ground_E: {0:.3f}'.format(ground_E)\n",
    "        plt.ylabel(\"Best Energy Post-MC\")\n",
    "        plt.xlabel(\"Total Time for MC\")\n",
    "        plt.xlim(0, taus_mcbb[-1]*1.01)\n",
    "        plt.ylim(ground_E  - abs(initial_E - ground_E) *0.01, initial_E + abs(initial_E - ground_E) *0.01)\n",
    "        plt.plot(taus_mcbb, Es_mcbb,label='MCBB', lw=4, c='red')\n",
    "        plt.plot(taus_mcbb, ground_E_line,label=ground_label, lw=5, c='black')\n",
    "        if(j_change >-1): plt.scatter(taus_mcbb[j_change], Es_mcbb[j_change],label='j_change:', s=100, c='blue')\n",
    "        if(k_change >-1): plt.scatter(taus_mcbb[k_change], Es_mcbb[k_change],label='k_change:', s=100, c='green')\n",
    "        plt.legend()\n",
    "        \n",
    "        \n",
    "        if(save):\n",
    "            dir = \"figures/\" + lattice_params\n",
    "            if not os.path.exists(dir): os.makedirs(dir) \n",
    "            plt.savefig(dir + \"/\" + unique_params + \".pdf\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "def plot_gap_vs_tau(data_mcbb_whole,save): \n",
    "    plt.figure()\n",
    "    for data_mcbb_per_file in data_mcbb_whole[1]:\n",
    "        min_tau_mcbb, min_seed_mcbb, min_time_index_mcbb = get_optimal_tau_seed_index(data_mcbb_per_file)\n",
    "        tau = get_values(data_mcbb_per_file, \"taus\")[min_time_index_mcbb]\n",
    "        if(tau == 0.005): continue\n",
    "        ground_E = get_values(data_mcbb_per_file, \"ground_Es\")[min_time_index_mcbb]\n",
    "        initial_E = get_values(data_mcbb_per_file, \"initial_Es\")[min_time_index_mcbb]\n",
    "        initial_E2 = get_values(data_mcbb_per_file, \"best_E_arrays\")[min_time_index_mcbb][1]\n",
    "        gap = initial_E - ground_E\n",
    "        gap2 = initial_E2 - ground_E\n",
    "        \n",
    "        plt.scatter(tau, gap, c = 'blue')\n",
    "        plt.scatter(tau, gap2, c = 'red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_everything_for_initial(data_mcbb_whole,save): \n",
    "    ji_list = [0.05, 0.95]\n",
    "    ki_list = [0.05, 0.95]\n",
    "\n",
    "    for dir_ in my_dirs:\n",
    "\n",
    "        lattice = (((dir_).split(\"data/\"))[-1])\n",
    "        lattice = lattice[:len(lattice)-1]\n",
    "        \n",
    "        for ji in ji_list:\n",
    "            for ki in ki_list:\n",
    "\n",
    "                same_initial_indices = []\n",
    "                for x in range(len(data_mcbb_whole[1])):\n",
    "                    ji2 = float(get_values(get_values(data_mcbb_whole[1][x], \"parameters\"), \"j_initial\"))\n",
    "                    ki2 = float(get_values(get_values(data_mcbb_whole[1][x], \"parameters\"), \"k_initial\"))\n",
    "                    lattice_params = ((data_mcbb_whole[0][x]).split(\"data/\")[1]).split(\"MCBB\")[0]\n",
    "                    if(ji==ji2 and ki==ki2 and lattice in lattice_params) : same_initial_indices.append(x)\n",
    "     \n",
    "                \n",
    "                jt,kt,tau_critical,j_jumps, k_jumps, target_E, init_E = [],[],[],[],[],[],[]\n",
    "                char_j_1, char_j_0, char_k_1, char_k_0 = [],[],[],[]\n",
    "                char_j_1_tau, char_j_0_tau, char_k_1_tau, char_k_0_tau,state_overlap_squared = [],[],[],[],[]\n",
    "                for x in range(len(same_initial_indices)):\n",
    "                    index = same_initial_indices[x]\n",
    "                    jt.append(float(get_values(get_values(data_mcbb_whole[1][index], \"parameters\"), \"j_target\")))\n",
    "                    kt.append(float(get_values(get_values(data_mcbb_whole[1][index], \"parameters\"), \"k_target\")))\n",
    "                    tau_critical.append(get_values(data_mcbb_whole[1][index], \"tau_array\")[-1])\n",
    "                    j_jumps.append(get_values(data_mcbb_whole[1][index], \"j_jumps\")[-1])\n",
    "                    k_jumps.append(get_values(data_mcbb_whole[1][index], \"k_jumps\")[-1])\n",
    "                    target_E.append(float(get_values(get_values(data_mcbb_whole[1][index], \"parameters\"), 'GROUND_E')))\n",
    "                    init_E.append(float(get_values(get_values(data_mcbb_whole[1][index], \"parameters\"), 'INITIAL_E')))\n",
    "                    char_j_1.append((get_values(data_mcbb_whole[1][index], \"j_char_time\"))[0])\n",
    "                    char_j_0.append((get_values(data_mcbb_whole[1][index], \"j_char_time\"))[1])\n",
    "                    char_k_1.append((get_values(data_mcbb_whole[1][index], \"k_char_time\"))[0])\n",
    "                    char_k_0.append((get_values(data_mcbb_whole[1][index], \"k_char_time\"))[1])\n",
    "                    char_j_1_tau.append((get_values(data_mcbb_whole[1][index], \"j_char_time_over_tau\"))[0])\n",
    "                    char_j_0_tau.append((get_values(data_mcbb_whole[1][index], \"j_char_time_over_tau\"))[1])\n",
    "                    char_k_1_tau.append((get_values(data_mcbb_whole[1][index], \"k_char_time_over_tau\"))[0])\n",
    "                    char_k_0_tau.append((get_values(data_mcbb_whole[1][index], \"k_char_time_over_tau\"))[1])\n",
    "                    state_overlap_squared.append(float(get_values(get_values(data_mcbb_whole[1][index], \"parameters\"), 'state_overlap_squared')))\n",
    "\n",
    "                    \n",
    "                fig = plt.figure(figsize=(8,28))\n",
    "                lattice_params = ((data_mcbb_whole[0][same_initial_indices[0]]).split(\"data/\")[1]).split(\"MCBB\")[0]\n",
    "                fig.suptitle(str(lattice_params) + \"_ji: \"+str(ji)+\", ki: \"+ str(ki))\n",
    "                \n",
    "                if(\"4_occupants\" in lattice_params and ji!=ki): dimension = 13\n",
    "                else: dimension = 7\n",
    "                \n",
    "                \n",
    "                '''\n",
    "                PLOTTING TAU\n",
    "                '''\n",
    "                fig.add_subplot(7, 2, 1)\n",
    "                plt.title(\"tau_critical\")\n",
    "                #plt.ylabel(\"kt\"),plt.xlabel(\"jt\")\n",
    "                plt.yticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95]),plt.xticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95])\n",
    "                plt.imshow((np.reshape(tau_critical, (dimension, dimension)).T)[::-1],extent=[-.025,1.025,-.025,1.025], cmap=cmap)\n",
    "                cbar = plt.colorbar()\n",
    "                \n",
    "                '''\n",
    "                PLOTTING STATE OVERLAP\n",
    "                '''              \n",
    "                fig.add_subplot(7, 2, 2)\n",
    "                plt.title(\"state_overlap_squared\")\n",
    "                #plt.ylabel(\"kt\"),plt.xlabel(\"jt\")\n",
    "                plt.yticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95]),plt.xticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95])\n",
    "                plt.imshow((np.reshape(state_overlap_squared, (dimension, dimension)).T)[::-1],extent=[-.025,1.025,-.025,1.025], cmap=cmap)\n",
    "                cbar = plt.colorbar()\n",
    "                \n",
    "                '''\n",
    "                PLOTTING EDIF\n",
    "                '''\n",
    "                fig.add_subplot(7, 2, 3)\n",
    "                plt.title(\"E_init-E_ground\")\n",
    "                #plt.ylabel(\"kt\"),plt.xlabel(\"jt\")\n",
    "                plt.yticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95]),plt.xticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95])\n",
    "                plt.imshow((np.reshape(np.array(init_E)-np.array(target_E), (dimension, dimension)).T)[::-1],extent=[-.025,1.025,-.025,1.025], cmap=cmap)\n",
    "                cbar = plt.colorbar()\n",
    "                fig.add_subplot(7, 2, 4)\n",
    "                plt.title(\"E_ground\")\n",
    "                #plt.ylabel(\"kt\"),plt.xlabel(\"jt\")\n",
    "                plt.yticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95]),plt.xticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95])\n",
    "                plt.imshow((np.reshape(target_E, (dimension, dimension)).T)[::-1],extent=[-.025,1.025,-.025,1.025], cmap=cmap)\n",
    "                cbar = plt.colorbar()\n",
    "                \n",
    "                \n",
    "                '''\n",
    "                PLOTTING J JUMPS\n",
    "                '''\n",
    "                norm = matplotlib.colors.BoundaryNorm(np.arange(-0.5,5.5,1), cmap.N)\n",
    "                fig.add_subplot(7, 2, 5)\n",
    "                plt.title(\"j_jumps\")\n",
    "                #plt.ylabel(\"kt\"),plt.xlabel(\"jt\")\n",
    "                plt.yticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95]),plt.xticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95])\n",
    "                #plt.scatter(jt, kt, c=j_jumps, s = 100,vmin=0, vmax=5, norm=norm)   \n",
    "                plt.imshow((np.reshape(j_jumps, (dimension, dimension)).T)[::-1],extent=[-.025,1.025,-.025,1.025],vmin=0, vmax=5,norm=norm, cmap=cmap)\n",
    "                cbar = plt.colorbar(ticks=np.linspace(0,5,6))\n",
    "\n",
    "                \n",
    "                \n",
    "                '''\n",
    "                PLOTTING K JUMPS\n",
    "                '''\n",
    "                fig.add_subplot(7, 2, 6)\n",
    "                plt.title(\"k_jumps\")\n",
    "                plt.ylabel(\"kt\"),plt.xlabel(\"jt\")\n",
    "                plt.yticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95]),plt.xticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95])\n",
    "                #plt.scatter(jt, kt, c=k_jumps, s = 100,vmin=0, vmax=5, norm=norm)   \n",
    "                plt.imshow((np.reshape(k_jumps, (dimension, dimension)).T)[::-1],extent=[-.025,1.025,-.025,1.025],vmin=0, vmax=5, norm=norm, cmap=cmap)\n",
    "                cbar = plt.colorbar(ticks=np.linspace(0,5,6))\n",
    "                \n",
    "                \n",
    "                '''\n",
    "                PLOTTING JCHAR_TAU\n",
    "                '''\n",
    "                fig.add_subplot(7, 2, 7)\n",
    "                plt.title(\"j_char_1_over_tau\")\n",
    "                #plt.ylabel(\"kt\"),plt.xlabel(\"jt\")\n",
    "                plt.yticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95]),plt.xticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95])\n",
    "                plt.imshow((np.reshape(char_j_1_tau, (dimension, dimension)).T)[::-1],extent=[-.025,1.025,-.025,1.025], cmap=cmap)\n",
    "                cbar = plt.colorbar(ticks=np.linspace(0,1,5))\n",
    "                \n",
    "                fig.add_subplot(7, 2, 8)\n",
    "                plt.title(\"j_char_0_over_tau\")\n",
    "                #plt.ylabel(\"kt\"),plt.xlabel(\"jt\")\n",
    "                plt.yticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95]),plt.xticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95])\n",
    "                plt.imshow((np.reshape(char_j_0_tau, (dimension, dimension)).T)[::-1],extent=[-.025,1.025,-.025,1.025], cmap=cmap)\n",
    "                cbar = plt.colorbar(ticks=np.linspace(0,1,5))\n",
    "                \n",
    "                \n",
    "                '''\n",
    "                PLOTTING JCHAR\n",
    "                '''\n",
    "                fig.add_subplot(7, 2, 9)\n",
    "                plt.title(\"j_char_1\")\n",
    "                #plt.ylabel(\"kt\"),plt.xlabel(\"jt\")\n",
    "                plt.yticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95]),plt.xticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95])\n",
    "                plt.imshow((np.reshape(char_j_1, (dimension, dimension)).T)[::-1],extent=[-.025,1.025,-.025,1.025],cmap=cmap)\n",
    "                cbar = plt.colorbar()\n",
    "\n",
    "                fig.add_subplot(7, 2, 10)\n",
    "                plt.title(\"j_char_0\")\n",
    "                #plt.ylabel(\"kt\"),plt.xlabel(\"jt\")\n",
    "                plt.yticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95]),plt.xticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95])\n",
    "                plt.imshow((np.reshape(char_j_0, (dimension, dimension)).T)[::-1],extent=[-.025,1.025,-.025,1.025], cmap=cmap)\n",
    "                cbar = plt.colorbar()\n",
    "                '''\n",
    "                PLOTTING kCHAR_TAU\n",
    "                '''\n",
    "                fig.add_subplot(7, 2, 11)\n",
    "                plt.title(\"k_char_1_over_tau\")\n",
    "                #plt.ylabel(\"kt\"),plt.xlabel(\"jt\")\n",
    "                plt.yticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95]),plt.xticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95])\n",
    "                plt.imshow((np.reshape(char_k_1_tau, (dimension, dimension)).T)[::-1],extent=[-.025,1.025,-.025,1.025], cmap=cmap)\n",
    "                cbar = plt.colorbar(ticks=np.linspace(0,1,5))\n",
    "                \n",
    "                fig.add_subplot(7, 2, 12)\n",
    "                plt.title(\"k_char_0_over_tau\")\n",
    "                #plt.ylabel(\"kt\"),plt.xlabel(\"jt\")\n",
    "                plt.yticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95]),plt.xticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95])\n",
    "                plt.imshow((np.reshape(char_k_0_tau, (dimension, dimension)).T)[::-1],extent=[-.025,1.025,-.025,1.025], cmap=cmap)\n",
    "                cbar = plt.colorbar(ticks=np.linspace(0,1,5))\n",
    "                \n",
    "                '''\n",
    "                PLOTTING kCHAR_TAU\n",
    "                '''\n",
    "                fig.add_subplot(7, 2, 13)\n",
    "                plt.title(\"k_char_1\")\n",
    "                #plt.ylabel(\"kt\"),plt.xlabel(\"jt\")\n",
    "                plt.yticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95]),plt.xticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95])\n",
    "                plt.imshow((np.reshape(char_k_1, (dimension, dimension)).T)[::-1],extent=[-.025,1.025,-.025,1.025], cmap=cmap)\n",
    "                cbar = plt.colorbar()\n",
    "                \n",
    "                fig.add_subplot(7, 2, 14)\n",
    "                plt.title(\"k_char_0\")\n",
    "                #plt.ylabel(\"kt\"),plt.xlabel(\"jt\")\n",
    "                plt.yticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95]),plt.xticks([0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95])\n",
    "                plt.imshow((np.reshape(char_k_0, (dimension, dimension)).T)[::-1],extent=[-.025,1.025,-.025,1.025], cmap=cmap)\n",
    "                cbar = plt.colorbar()\n",
    "                \n",
    "                if(save):\n",
    "                    dir = \"figures/\" + lattice_params\n",
    "                    if not os.path.exists(dir): os.makedirs(dir) \n",
    "                    plt.savefig(dir + \"/ji_\" + str(ji) + \"_ki_\" +str(ki) + \".pdf\")\n",
    "                plt.show()               \n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directories holding the data we're interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_dirs = ['../data/3x3/2_occupants/','../data/3x3/3_occupants/',\n",
    "#            '../data/3x3/4_occupants/','../data/3x3/7_occupants/']  \n",
    "\n",
    "#my_dirs = ['../data/3x3/4_occupants/'] \n",
    "\n",
    "my_dirs = ['../data/2x2/2_occupants/','../data/3x3/2_occupants/',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing/ignoring very small pulses which are smaller than COLLAPSE_LIMIT_FRACTION*TAU\n",
    "COLLAPSE_LIMIT_FRACTION = 0.03    \n",
    "\n",
    "#The E vs Tau is traditionally non-linear globally, but roughly linear closer to critical tau\n",
    "#This allows line fitting to include points with taus ranging from [(1-DISTANCE_LIMIT)*TAU, TAU]\n",
    "DISTANCE_LIMIT = 0.4              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'Main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mcbb_whole, data_mcdb_whole, data_mcbf_whole, data_adia_whole = get_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_all_data(data_mcbb_whole, data_mcdb_whole, data_mcbf_whole, data_adia_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "plot_everything_for_initial(data_mcbb_whole,save)\n",
    "# plot_data(data_mcbb_whole,data_1mcbf_whole,data_adia_whole, save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Reminders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parameters', 'j_protocols', 'k_protocols', 'b_protocols', 'tau_array', 'best_E_array', 'distance_array', 'j_protocols_reduced', 'k_protocols_reduced', 'b_protocols_reduced', 'j_jumps', 'k_jumps', 'b_jumps', 'j_char_time', 'j_char_time_over_tau', 'k_char_time', 'k_char_time_over_tau', 'b_char_time', 'b_char_time_over_tau']\n",
      "\n",
      "[[['DIAG', 'NUM_SEEDS', 'DISTANCE_LIMIT_MCBB', 'TAU_INIT_MCBB', 'MAX_TAU_MCBB', 'TAU_SCALAR_MCBB', 'TAU_SCALAR_MCBB_TINY', 'TAU_SCALAR_MCBB_BIG', 'MAX_CHANGE_FRACTION_MCBB', 'MIN_CHANGE_FRACTION_MCBB', 'ACCEPTANCE_PROB_MCBB', 'TEMP_EXP_DECAY_MCBB', 'BINARY_SEARCH_TAU_LIMIT_MCBB', 'RANDOM_STATES_MCBB', 'NUMBER_OF_BANGS', 'SWEEPS_MCBB', 'TEMP_DECAY_ITERATIONS_MCBB', 'TEMP_DECAY_LIMIT_MCBB', 'MAX_TAU_STEPS_MCBB', 'MAX_BS_STEPS_MCDB', 'GROUND_E', 'INITIAL_E', 'j_initial', 'k_initial', 'b_initial', 'j_target', 'k_target', 'b_target', 'state_overlap_squared', 'PERIODIC', 'UNIFORM_SITES', 'DEVICE_DIMENSION', 'MAX_PARAM', 'MIN_PARAM'], ['false', '4', '0.02', '0.05', '0.8', '1.3', '1.1', '1.8', '0.8', '0.02', '0.8', '0.8', '0.0005', '3', '3', '70', '20', '7', '11', '9', '-0.731012', '-0.731012', '0.05', '0.05', '0', '0.05', '0.05', '0', '1', 'true', 'true', '2', '1', '0']], [[0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0]], [0.0], [0.0], [0.0], [[0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0]], [0], [0], [0], [0, 0], [0.0, 0.0], [0, 0], [0.0, 0.0], [0, 0], [0.0, 0.0]]\n",
      "\n",
      "[['DIAG', 'NUM_SEEDS', 'DISTANCE_LIMIT_MCBB', 'TAU_INIT_MCBB', 'MAX_TAU_MCBB', 'TAU_SCALAR_MCBB', 'TAU_SCALAR_MCBB_TINY', 'TAU_SCALAR_MCBB_BIG', 'MAX_CHANGE_FRACTION_MCBB', 'MIN_CHANGE_FRACTION_MCBB', 'ACCEPTANCE_PROB_MCBB', 'TEMP_EXP_DECAY_MCBB', 'BINARY_SEARCH_TAU_LIMIT_MCBB', 'RANDOM_STATES_MCBB', 'NUMBER_OF_BANGS', 'SWEEPS_MCBB', 'TEMP_DECAY_ITERATIONS_MCBB', 'TEMP_DECAY_LIMIT_MCBB', 'MAX_TAU_STEPS_MCBB', 'MAX_BS_STEPS_MCDB', 'GROUND_E', 'INITIAL_E', 'j_initial', 'k_initial', 'b_initial', 'j_target', 'k_target', 'b_target', 'state_overlap_squared', 'PERIODIC', 'UNIFORM_SITES', 'DEVICE_DIMENSION', 'MAX_PARAM', 'MIN_PARAM'], ['false', '4', '0.02', '0.05', '0.8', '1.3', '1.1', '1.8', '0.8', '0.02', '0.8', '0.8', '0.0005', '3', '3', '70', '20', '7', '11', '9', '-0.731012', '-0.731012', '0.05', '0.05', '0', '0.05', '0.05', '0', '1', 'true', 'true', '2', '1', '0']]\n",
      "\n",
      "-0.731012\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "data_mcbb_whole[0][n] = name of nth file\n",
    "data_mcbb_whole[1][n] = data for the nth file\n",
    "\n",
    "\n",
    "letting data = data_mcbb_whole[1][n], the data for the nth file, get_values(data, 'NAME') will return\n",
    "the values associated with NAME for the nth file. The possible inputs for NAME are printed below:\n",
    "\n",
    "['parameters', 'j_protocols', 'k_protocols', 'b_protocols', 'tau_array', 'best_E_array', \n",
    "'distance_array', 'j_protocols_reduced', 'k_protocols_reduced', 'b_protocols_reduced', \n",
    "'j_jumps', 'k_jumps', 'b_jumps', 'j_char_time', 'j_char_time_over_tau', 'k_char_time', \n",
    "'k_char_time_over_tau', 'b_char_time', 'b_char_time_over_tau']\n",
    "'''\n",
    "\n",
    "print(data_mcbb_whole[1][0][0])\n",
    "print()\n",
    "print(data_mcbb_whole[1][0][1])\n",
    "print()\n",
    "print(get_values(data_mcbb_whole[1][0], \"parameters\"))\n",
    "print()\n",
    "print(get_values(get_values(data_mcbb_whole[1][0], \"parameters\"), 'GROUND_E'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parameters', 'j_protocols', 'k_protocols', 'b_protocols', 'tau_array', 'best_E_array', 'distance_array', 'total_steps_array', 'time_step_array']\n",
      "\n",
      "[[['NUM_SEEDS', 'DISTANCE_LIMIT_MCDB', 'TAU_INIT_MCDB', 'MAX_TAU_MCDB', 'TAU_SCALAR_MCDB', 'TAU_SCALAR_MCDB_TINY', 'TAU_SCALAR_MCDB_BIG', 'ACCEPTANCE_PROB_MCDB', 'TEMP_EXP_DECAY_MCDB', 'BINARY_SEARCH_TAU_LIMIT_MCDB', 'RANDOM_STATES_MCDB', 'TIME_STEP_MCDB', 'SWEEPS_MCDB', 'TEMP_DECAY_ITERATIONS_MCDB', 'TEMP_DECAY_LIMIT_MCDB', 'MAX_TAU_STEPS_MCDB', 'MAX_BS_STEPS_MCDB', 'GROUND_E', 'INITIAL_E', 'j_initial', 'k_initial', 'b_initial', 'j_target', 'k_target', 'b_target', 'state_overlap_squared', 'PERIODIC', 'UNIFORM_SITES', 'DEVICE_DIMENSION', 'MAX_PARAM', 'MIN_PARAM'], ['4', '0.02', '0.05', '1', '1.1', '1.05', '1.2', '0.8', '0.8', '0.0005', '3', '0.01', '70', '20', '7', '32', '8', '-0.273205', '-0.273205', '0.05', '0.05', '0', '0.05', '0.05', '0', '1', 'false', 'true', '2', '1', '0']], [[0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0]], [0.0], [0.0], [0.0], [5], [0.01]]\n",
      "\n",
      "[['NUM_SEEDS', 'DISTANCE_LIMIT_MCDB', 'TAU_INIT_MCDB', 'MAX_TAU_MCDB', 'TAU_SCALAR_MCDB', 'TAU_SCALAR_MCDB_TINY', 'TAU_SCALAR_MCDB_BIG', 'ACCEPTANCE_PROB_MCDB', 'TEMP_EXP_DECAY_MCDB', 'BINARY_SEARCH_TAU_LIMIT_MCDB', 'RANDOM_STATES_MCDB', 'TIME_STEP_MCDB', 'SWEEPS_MCDB', 'TEMP_DECAY_ITERATIONS_MCDB', 'TEMP_DECAY_LIMIT_MCDB', 'MAX_TAU_STEPS_MCDB', 'MAX_BS_STEPS_MCDB', 'GROUND_E', 'INITIAL_E', 'j_initial', 'k_initial', 'b_initial', 'j_target', 'k_target', 'b_target', 'state_overlap_squared', 'PERIODIC', 'UNIFORM_SITES', 'DEVICE_DIMENSION', 'MAX_PARAM', 'MIN_PARAM'], ['4', '0.02', '0.05', '1', '1.1', '1.05', '1.2', '0.8', '0.8', '0.0005', '3', '0.01', '70', '20', '7', '32', '8', '-0.273205', '-0.273205', '0.05', '0.05', '0', '0.05', '0.05', '0', '1', 'false', 'true', '2', '1', '0']]\n",
      "\n",
      "-0.273205\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "data_mcdb_whole[0][n] = name of nth file\n",
    "data_mcdb_whole[1][n] = data for the nth file\n",
    "\n",
    "\n",
    "letting data = data_mcdb_whole[1][n], the data for the nth file, get_values(data, 'NAME') will return\n",
    "the values associated with NAME for the nth file. The possible inputs for NAME are printed below:\n",
    "\n",
    "['parameters', 'j_protocols', 'k_protocols', 'b_protocols', 'tau_array', 'best_E_array', \n",
    "'distance_array', 'j_protocols_reduced', 'k_protocols_reduced', 'b_protocols_reduced', \n",
    "'j_jumps', 'k_jumps', 'b_jumps', 'j_char_time', 'j_char_time_over_tau', 'k_char_time', \n",
    "'k_char_time_over_tau', 'b_char_time', 'b_char_time_over_tau']\n",
    "'''\n",
    "\n",
    "print(data_mcdb_whole[1][0][0])\n",
    "print()\n",
    "print(data_mcdb_whole[1][0][1])\n",
    "print()\n",
    "print(get_values(data_mcdb_whole[1][0], \"parameters\"))\n",
    "print()\n",
    "print(get_values(get_values(data_mcdb_whole[1][0], \"parameters\"), 'GROUND_E'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAVEYARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appending the state overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../data/overlap.txt\", 'r') as file:\n",
    "#     data = file.readlines()\n",
    "#     for line in data:\n",
    "#         line = line.rstrip('\\n').split(\" \")\n",
    "#         num = line[0]\n",
    "#         ji = line[1]\n",
    "#         ki = line[2]\n",
    "#         jt = line[3]\n",
    "#         kt = line[4]\n",
    "#         state_overlap = line[5]\n",
    "#         path = \"../data/3x3/\"+num+\"_occupants/MCBB___PBC=t_UNI=t_DD=2___ji=\"+ji+\"_ki=\"+ki+\"_jt=\"+jt+\"_kt=\"+kt#+\".txt\"\n",
    "#         conditions = [num]\n",
    "#         for filepath in glob.iglob(\"../data/3x3/\"+num+\"_occupants/\" + '*.txt'):\n",
    "#             conditions = [num+\"_occu\" in filepath,\n",
    "#                          \"ji=\"+ji in filepath,\n",
    "#                          \"ki=\"+ki in filepath,\n",
    "#                          \"jt=\"+jt in filepath,\n",
    "#                          \"kt=\"+kt in filepath,]\n",
    "#             if(all(conditions)):\n",
    "#                 f=open(filepath, \"r\")\n",
    "#                 contents = f.readlines()\n",
    "#                 f.close()\n",
    "#                 if(\"state_overlap\" in contents[29]): contents[29]=\"state_overlap_squared =    \"+state_overlap+\"\\n\"\n",
    "#                 else: contents.insert(29, \"state_overlap_squared =    \"+state_overlap+\"\\n\")\n",
    "#                 f = open(filepath, \"w\")\n",
    "#                 contents = \"\".join(contents)\n",
    "#                 f.write(contents)\n",
    "#                 f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ji=0.05 ki=0.05 jt=0.5 kt=0.95\n",
      "tau=0.532091  best_E=-7.46092\n",
      "new Tau = 0.5059985\n",
      "New j=\n",
      "[0.053341200000000005, 0.207361, 0.2827445, 0.42718500000000004]\n",
      "New k=\n",
      "[0.00540225, 0.437875]\n"
     ]
    }
   ],
   "source": [
    "#for the interpolation, we want:\n",
    "#tau, the time of the nearest neighbor jumps, the best energy\n",
    "#a nice way to save the old data and add on the new jumps\n",
    "# input the jumps of two neighbors in either direction\n",
    "\n",
    "def get_data_set(data_mcbb_whole, dir_, ji, ki, jt, kt):\n",
    "    index = []\n",
    "    for x in range(len(data_mcbb_whole[0])):\n",
    "        conditions = [\"ji=\"+str(ji) in data_mcbb_whole[0][x], \n",
    "                      \"ki=\"+str(ki) in data_mcbb_whole[0][x],\n",
    "                      \"jt=\"+str(jt) in data_mcbb_whole[0][x],\n",
    "                      \"kt=\"+str(kt) in data_mcbb_whole[0][x],\n",
    "                      dir_ in data_mcbb_whole[0][x]]\n",
    "        if(all(conditions)): index.append(x)\n",
    "    if(len(index) != 1):print(\"\\n\\nERROR\\n\\n\")\n",
    "    else: return data_mcbb_whole[1][index[0]]\n",
    "    \n",
    "my_dirs = ['../data/3x3/3_occupants']  \n",
    "interpolation_info = [[0.05, 0.05, [[0.35,0.95], [0.65, 0.95]], \"j\"],\n",
    "                     ]\n",
    "for interp_set in interpolation_info:\n",
    "    ji = interp_set[0]\n",
    "    ki = interp_set[1]\n",
    "    target1 = interp_set[2][0]\n",
    "    target2 = interp_set[2][1]\n",
    "    j_or_k = interp_set[3]\n",
    "    jt1, kt1 = target1[0], target1[1]\n",
    "    jt2, kt2 = target2[0], target2[1]\n",
    "    data1 = get_data_set(data_mcbb_whole, my_dirs[0], ji, ki, jt1, kt1)\n",
    "    data2 = get_data_set(data_mcbb_whole, my_dirs[0], ji, ki, jt2, kt2)\n",
    "    data_to_change = get_data_set(data_mcbb_whole, my_dirs[0], ji, ki, (jt1+jt2)/2, (kt1+kt2)/2)\n",
    "\n",
    "    p1 = get_values(data1, \"j_protocols_reduced\")[-1]\n",
    "    p2 = get_values(data2, \"j_protocols_reduced\")[-1]\n",
    "\n",
    "    if(len(p1) != len(p2)): print(\"ERROR, Protocols don't have the same number of jumps\")\n",
    "    new_j_jumps = []\n",
    "    for t1, t2 in zip(p1, p2):\n",
    "        new_j_jumps.append((t1+t2)/2)\n",
    "        \n",
    "    p1 = get_values(data1, \"k_protocols_reduced\")[-1]\n",
    "    p2 = get_values(data2, \"k_protocols_reduced\")[-1]\n",
    "\n",
    "    if(len(p1) != len(p2)): print(\"ERROR, Protocols don't have the same number of jumps\")\n",
    "    new_k_jumps = []\n",
    "    for t1, t2 in zip(p1, p2):\n",
    "        new_k_jumps.append((t1+t2)/2)\n",
    "        \n",
    "    print(\"\\nji=\"+str(ji)+\" ki=\"+str(ki)+\" jt=\"+str((jt1+jt2)/2)+\" kt=\"+str((kt1+kt2)/2))\n",
    "    print(\"tau=\"+str(get_values(data_to_change, \"tau_array\")[-1])+\"  best_E=\"+str(get_values(data_to_change, \"best_E_array\")[-1]))\n",
    "#     print(\"Old j=\")\n",
    "#     print(get_values(data_to_change, \"j_protocols_reduced\")[-1])\n",
    "#     print(\"Old k=\")\n",
    "#     print(get_values(data_to_change, \"k_protocols_reduced\")[-1])\n",
    "    print(\"new Tau = \" + str((get_values(data1, \"tau_array\")[-1]+get_values(data2, \"tau_array\")[-1])/2))\n",
    "    print(\"New j=\")\n",
    "    print(new_j_jumps)\n",
    "    print(\"New k=\")\n",
    "    print(new_k_jumps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Gap Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gap():\n",
    "    filepath = '../data/gap.txt'\n",
    "    j, k, gap = [],[],[]\n",
    "    \n",
    "    for line in open(filepath, \"rt\"):     \n",
    "        line = line.rstrip(\"\\n\")\n",
    "        if line.startswith('gap'): gap.append(literal_eval((line.split('=')[-1]).replace(\" \", \"\")))\n",
    "        elif line.startswith('j'):   j.append(literal_eval((line.split('=')[-1]).replace(\" \", \"\")))\n",
    "        elif line.startswith('k'):   k.append(literal_eval((line.split('=')[-1]).replace(\" \", \"\")))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.ylabel(\"k\")\n",
    "    plt.xlabel(\"j\")\n",
    "    plt.ylim(-0.05,1.05)\n",
    "    plt.ylim(-0.05,1.05)\n",
    "    plt.scatter(j, k, c=gap, cmap = cmap, s = 10, alpha=0.7)\n",
    "    cbar = plt.colorbar(label = 'gap')\n",
    "    #plt.scatter(0.1, 0.1, s = 100, c = 'pink', label = 'initial')\n",
    "    #plt.scatter(1, 1, s = 100, c = 'black', label = 'target')\n",
    "    #plt.legend()\n",
    "    plt.savefig(\"../data/gap_plot_3x3_4_occ.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "plot_gap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lattice_size = 6\n",
    "'''Rectangular Lattice\n",
    "for n in range(2,max_lattice_size+1):\n",
    "    for m in range(2,max_lattice_size+1):\n",
    "        for x in  range(2, m*n-1):\n",
    "            if(m>=n): #preventing creation of both mxn and nxm\n",
    "                dir = '../data/'+str(n)+'x'+str(m)+'/'+str(x)+'_occupants'\n",
    "                if not os.path.exists(dir):\n",
    "                    os.makedirs(dir)\n",
    "'''\n",
    "#Square Lattice\n",
    "for n in range(2,max_lattice_size+1):\n",
    "    for x in  range(2, n*n-1):\n",
    "        dir = '../data/'+str(n)+'x'+str(n)+'/'+str(x)+'_occupants'\n",
    "        if not os.path.exists(dir):\n",
    "            os.makedirs(dir)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
